# Connectâ€‘4â€‘AI

> **Play, train & compare AI agents for the classic Connectâ€¯Four** â€” ID3 decision trees, ensemble bagging, and (parallel) Monteâ€‘Carlo Tree Search implemented in pure Python and orchestrated from a single Jupyter notebook.

---

## âœ¨ Features at a glance

| Category                  | Highlights                                                                                                                                                                                                             |
| ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Game engine**           | 6â€¯Ã—â€¯7 ConnectÂ Four with full rule enforcement & win detection (Python) + terminal UI                                                                                                                                   |
| **Game modes**            | â€¢ PlayerÂ vsÂ Player  â€¢ PlayerÂ vsÂ Computer  â€¢ ComputerÂ vsÂ Computer                                                                                                                                                       |
| **AI agents**             | â‘  *Random* baseline <br>â‘¡ *ID3 Decision Tree* trained from selfâ€‘play logs <br>â‘¢ *Decisionâ€‘Tree Ensemble* (bootstrap + majority vote) <br>â‘£ *Monteâ€‘Carlo Tree Search* (UCT) <br>â‘¤ *Parallel MCTS* via `multiprocessing` |
| **Learning loop**         | Every finished match is appended to `datasets/match_log.csv`; choosing a treeâ€‘based agent triggers automatic reâ€‘training                                                                                               |
| **Visualisation**         | Graphviz exports for decision trees & MCTS trees, plus matplotlib winâ€‘rate plots                                                                                                                                       |
| **Reproducible notebook** | `connect_four.ipynb` runs all experiments and produces the figures you see in `images/`                                                                                                                                |

---

## ğŸš€ Quick start

### 1Â Â Install requirements

```bash
# clone the repo
git clone https://github.com/<yourâ€‘user>/Connectâ€‘4â€‘AI.git
cd Connectâ€‘4â€‘AI

# optional: create a virtualâ€‘env
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# install Python packages
pip install -r requirements.txt
```

> **Graphviz** must be available **systemâ€‘wide** for the export helpers to work â€” e.g. `sudo apt install graphviz` (Linux) or install from [https://graphviz.org/download](https://graphviz.org/download) and add `bin/` to `%PATH%` (Windows).

### 2Â Â Run from the terminal

The runnable script lives inside the subâ€‘folder **`NanahiraÂ ConnectÂ 4!/main.py`**:

```bash
python "Nanahira Connect 4!/main.py"
```

Follow the interactive menu to pick a game mode and choose an AI for each player.

### 3Â Â Reproduce the notebook experiments

Open **`connect_four.ipynb`** in Jupyter Lab/Notebook and execute the cells.  The notebook will:

* launch configurable matchâ€‘ups (e.g. *Random vs MCTS*, *DT vs Ensemble*),
* log every move to `datasets/`,
* create diagrams under `images/` and model snapshots (`*.pkl`, `*.hash`) under **`NanahiraÂ ConnectÂ 4!/`**.

---

## ğŸ“ Repository layout

```text
Connectâ€‘4â€‘AI/
â”œâ”€â”€ datasets/                 # CSV logs & benchmark datasets
â”‚   â”œâ”€â”€ baddata.csv
â”‚   â”œâ”€â”€ big.csv
â”‚   â”œâ”€â”€ imbalanced.csv
â”‚   â”œâ”€â”€ match_log.csv         # grows after every game
â”‚   â”œâ”€â”€ mixed.csv
â”‚   â””â”€â”€ performance_log.csv
â”œâ”€â”€ images/                   # Graphviz & matplotlib outputs
â”‚   â”œâ”€â”€ mcts_root.png
â”‚   â”œâ”€â”€ mcts_tree.png
â”‚   â”œâ”€â”€ minha_arvore.dot
â”‚   â””â”€â”€ minha_arvore.png
â”œâ”€â”€ NanahiraÂ ConnectÂ 4!/      # main application package
â”‚   â”œâ”€â”€ Assets/               # (if using Unity â€“ otherwise ignore)
â”‚   â”œâ”€â”€ Nanahira/             # src package
â”‚   â”œâ”€â”€ main.py               # â† entry point used by the README
â”‚   â”œâ”€â”€ main.spec             # PyInstaller spec (for binary builds)
â”‚   â”œâ”€â”€ match_log.csv         # separate log for this build
â”‚   â”œâ”€â”€ trees_p*_*.pkl        # pickled decisionâ€‘tree models
â”‚   â””â”€â”€ trees_p*_*.hash       # saved model hashes
â”œâ”€â”€ References/               # playground & example notebooks
â”‚   â”œâ”€â”€ iris_decision_tree.ipynb
â”‚   â””â”€â”€ iris.csv
â”œâ”€â”€ connect_four.ipynb        # master notebook (same code as main.py but with experiments)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                 # you are here
```

*(Folder names with spaces are quoted in shell commands above for safety.)*

---

## ğŸ§  Inside the code

1. **State representation** â€” `State` tracks the 6â€¯Ã—â€¯7 board, legal moves, current player and winner status.
2. **Feature engineering** â€” each candidate column is described by five boolean/int features:

   * immediate win (`f0`)
   * blocks opponent win (`f1`)
   * forms exactly one 3â€‘inâ€‘aâ€‘row (`f2`)
   * prevents opponent threat (`f3`)
   * centreâ€‘column bonus (`f4`)
3. **ID3 Decision Tree** â€” implemented from scratch with entropy & informationâ€‘gain splitting; predicts the *index inside* `available_moves`.
4. **Bagging Ensemble** â€” `train_ensemble` bootstraps *N* trees and `make_ensemble_ai` applies majority vote.
5. **Monteâ€‘Carlo Tree Search** â€” UCT selection, backâ€‘prop with configurable reward (win=1, draw=0 or 0.5) and optional parallel rollâ€‘outs.
6. **Selfâ€‘play logging** â€” every completed game is flattened and appended to CSV; models are retrained on next invocation.

---

## ğŸ“Š Example benchmark results

| Matchâ€‘up (100 games)                    | WinÂ %Â P1 | WinÂ %Â P2 | DrawÂ % |
| --------------------------------------- | -------: | -------: | -----: |
| Random vs Random                        |     51.0 |     49.0 |    0.0 |
| Random vs MCTS (100 epochs)             |     4.0 |     96.0 |    0.0 |
| Random vs Parallel-MCTS (100 epochs)    |     6.0 |     94.0 |    0.0 |
| Parallelâ€‘MCTS (100) vs Itself           |     56.0 |     44.0 |    0.0 |
| Parallelâ€‘MCTS (100) vs Itself (Reward Draw=0.5)          |     63.0 |     37.0 |    0.0 |
| Parallelâ€‘MCTS (100) vs Itself (C=1)          |     62.0 |     38.0 |    0.0 |
| Parallelâ€‘MCTS (100) vs Itself (C=2)          |     70.0 |     30.0 |    0.0 |
| Parallelâ€‘MCTS (100) vs Itself (MaxChildrenExpandedNodes=4)          |     70.0 |     30.0 |    0.0 |
| Parallelâ€‘MCTS (100) vs (1000 epochs)    |     19.0 |     81.0 |    0.0 |
| Decision Tree (Bad dataset by random simulation) vs Random  |     53.0 |     47.0 |    0.0 |
| Decision Tree (Mixed dataset mostly by MC) vs Random  |     86.0 |     14.0 |    0.0 |
| Decision Tree (Big dataset only by MC) vs MC  |     26.0 |     74.0 |    0.0 |
| Decision Tree (Mixed) vs Ensemble Vote (Mixed)  |     24.0 |     76.0 |    0.0 |

*(Your numbers will vary â€” run the notebook to reproduce.)*

---

## ğŸ› ï¸ Train on your own games

```python
import pandas as pd
from Nanahira.train import train_ensemble, build_feature_dataset  # adjust to your package structure

my_matches = pd.read_csv("datasets/my_match_log.csv")
ensemble = train_ensemble(my_matches, n_trees=7, max_depth=6)
```

---

## ğŸ¤ Contributing

1. Fork & clone your fork.
2. Create a feature branch `git checkout -b feat/myâ€‘feature`.
3. Run `ruff`/`flake8`, commit, push, and open a PR.

---

## ğŸ“„ License

Released under the **MIT License** â€” see `LICENSE`.

---

*Have fun exploring game AI!*
